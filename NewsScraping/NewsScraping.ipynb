{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99d28981-1ad0-42b3-be87-097527d35396",
   "metadata": {},
   "source": [
    "## Guardian News Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4383e0de-0e50-47a9-ba1f-452017b2dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardian_news_scraper(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    author = soup.find_all('a', attrs={'rel' : 'author'})[0].get_text()\n",
    "    date = soup.find_all('span', attrs={'class' : 'dcr-u0h1qy'})\n",
    "    if len(date)==0:\n",
    "        date = soup.find_all('div', attrs={'class' : 'dcr-18bzkx3'})\n",
    "    date=date[0].get_text()\n",
    "    \n",
    "    headline = soup.find_all('h1', attrs={'class' : 'dcr-y70mar'})[0].get_text()\n",
    "    standfirst = soup.find_all('div', attrs={'class' : 'dcr-1qt3dlu'})[0].get_text()\n",
    "    \n",
    "    text_elements = soup.find_all('p', attrs={'class' : 'dcr-1kas69x'})\n",
    "    extracted_text = ' '.join([element.get_text() for element in text_elements])\n",
    "    return {\n",
    "        \"headline\":headline,\n",
    "        \"standfirst\":standfirst,\n",
    "        \"author\":author,\n",
    "        \"date\":date,\n",
    "        \"text\":extracted_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b9620-e845-4c30-8afc-4a15e09b9da5",
   "metadata": {},
   "source": [
    "## Guardian Opinion Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04698a5d-c178-437c-b16e-e7d970d12c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardian_opinion_scraper(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    author = soup.find_all('a', attrs={'rel' : 'author'})[0].get_text()\n",
    "    date = soup.find_all('span', attrs={'class' : 'dcr-u0h1qy'}) + soup.find_all('div', attrs={'class' : 'dcr-18bzkx3'})+ soup.find_all('p', attrs={'class' : 'content__dateline'})\n",
    "    \n",
    "    date=date[0].get_text()    \n",
    "    headline = soup.find_all('h1', attrs={'class' : 'dcr-y70mar'}) + soup.find_all('h1', attrs={'class' : 'dcr-1xaevyx'}) + soup.find_all('h1', attrs={'class' : 'content__headline'})\n",
    "    headline=headline[0].get_text()    \n",
    "    standfirst = soup.find_all('div', attrs={'class' : 'content__standfirst'}) + soup.find_all('div', attrs={'class' : 'dcr-1qt3dlu'}) + soup.find_all('div', attrs={'class' : 'dcr-xq41iu'}) \n",
    "    standfirst = standfirst[0].get_text()\n",
    "    text_elements = soup.find_all('p', attrs={'class' : 'dcr-1kas69x'}) + soup.find_all('p', attrs={'class' : 'dcr-rysp4a'}) \n",
    "    extracted_text = ' '.join([element.get_text() for element in text_elements])\n",
    "    return {\n",
    "        \"headline\":headline,\n",
    "        \"standfirst\":standfirst,\n",
    "        \"author\":author,\n",
    "        \"date\":date,\n",
    "        \"text\":extracted_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f8ba32-f186-4986-ae03-a3b43ad6b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_urls(url):\n",
    "    response = requests.get(url)\n",
    "    articles=[]\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "        # Find all the articles on the page\n",
    "        articles = soup.find_all('a',  attrs={'data-link-name' : 'article',\"class\":\"fc-item__link\"})\n",
    "    return [a.get(\"href\") for a in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da188fb-0302-484a-bbf9-2f1414f8a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b27ebee2-a56e-4c32-bacc-b366a10caa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown Format\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "Unknown Format\n"
     ]
    }
   ],
   "source": [
    "jsons = []\n",
    "year=2023\n",
    "month=\"sep\"\n",
    "day=\"29\"\n",
    "opinion_url = f'https://www.theguardian.com/commentisfree/{year}/{month}/{day}/'\n",
    "date=f\"{year}_{month}_{day}\"\n",
    "ars = get_date_urls(opinion_url)\n",
    "path = \"/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/\"\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path+date)\n",
    "if not isExist:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(f\"{path+date}\")\n",
    "   print(f\"{path+date} is created!\")\n",
    "for url in ars:\n",
    "    name = \"_\".join(url.split(\"/\")[-1].split(\"-\"))\n",
    "    \n",
    "    if not os.path.exists(f\"{path+date}/{name}.json\"):\n",
    "        try:\n",
    "            article = guardian_opinion_scraper(url)\n",
    "            if len(article[\"text\"])>100:\n",
    "                with open(f\"{path+date}/{name}.json\", \"w\") as outfile:\n",
    "                    json.dump(article, outfile)\n",
    "        except:\n",
    "            print(\"Unknown Format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab97183-1d19-4314-a5c9-cdcaa82560a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "mapper={\n",
    "    \"01\":\"jan\",\n",
    "    \"02\":\"feb\",\n",
    "    \"03\":\"mar\",\n",
    "    \"04\":\"apr\",\n",
    "    \"05\":\"may\",\n",
    "    \"06\":\"jun\",\n",
    "    \"07\":\"jul\",\n",
    "    \"08\":\"aug\",\n",
    "    \"09\":\"sep\",\n",
    "    \"10\":\"oct\",\n",
    "    \"11\":\"nov\",\n",
    "    \"12\":\"dec\",\n",
    "}\n",
    "dates = pd.date_range(start=\"2020-01-01\",end=\"2023-11-28\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "390dc514-31df-4d6d-b801-4db334f97c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [str(date).split(\" \")[0].split(\"-\") for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ce5038-2a3c-48ee-85f6-22759a7da845",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [[date[0],mapper[date[1]],date[2]] for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f72849d-aa97-4cff-949a-35900086a6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_jan_01\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020 is created!\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan is created!\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/01 is created!\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "2020_jan_02\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/02 is created!\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "2020_jan_03\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/03 is created!\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "2020_jan_04\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/04 is created!\n",
      "2020_jan_05\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/05 is created!\n",
      "Unknown Format\n",
      "2020_jan_06\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/06 is created!\n",
      "Unknown Format\n",
      "2020_jan_07\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/07 is created!\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "2020_jan_08\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/08 is created!\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "2020_jan_09\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/09 is created!\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "2020_jan_10\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/10 is created!\n",
      "2020_jan_11\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/11 is created!\n",
      "Unknown Format\n",
      "2020_jan_12\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/12 is created!\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "2020_jan_13\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/13 is created!\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "2020_jan_14\n",
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2020/jan/14 is created!\n",
      "Unknown Format\n",
      "Unknown Format\n",
      "Unknown Format\n"
     ]
    }
   ],
   "source": [
    "for date in dates:\n",
    "    year=date[0]\n",
    "    month=date[1]\n",
    "    day=date[2]\n",
    "    opinion_url = f'https://www.theguardian.com/commentisfree/{year}/{month}/{day}/'\n",
    "    date=f\"{year}_{month}_{day}\"\n",
    "    print(date)\n",
    "    ars = get_date_urls(opinion_url)\n",
    "    path = \"/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/\"\n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(path+year)\n",
    "    if not isExist:\n",
    "       # Create a new directory because it does not exist\n",
    "       os.makedirs(f\"{path+year}\")\n",
    "       print(f\"{path+year} is created!\")\n",
    "    isExist = os.path.exists(path+year+\"/\"+month)\n",
    "    if not isExist:\n",
    "       # Create a new directory because it does not exist\n",
    "       os.makedirs(f\"{path+year}/{month}\")\n",
    "       print(f\"{path+year}/{month} is created!\")\n",
    "    isExist = os.path.exists(path+year+\"/\"+month+\"/\"+day)\n",
    "    if not isExist:\n",
    "       # Create a new directory because it does not exist\n",
    "       os.makedirs(f\"{path+year}/{month}/{day}\")\n",
    "       print(f\"{path+year}/{month}/{day} is created!\")\n",
    "    \n",
    "    for url in ars:\n",
    "        name = \"_\".join(url.split(\"/\")[-1].split(\"-\"))\n",
    "        \n",
    "        if not os.path.exists(f\"{path+year}/{month}/{day}/{name}.json\"):\n",
    "            try:\n",
    "                article = guardian_opinion_scraper(url)\n",
    "                if len(article[\"text\"])>100:\n",
    "                    with open(f\"{path+year}/{month}/{day}/{name}.json\", \"w\") as outfile:\n",
    "                        json.dump(article, outfile)\n",
    "            except:\n",
    "                print(\"Unknown Format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "91b92793-80c0-432f-b260-f31e9cb0d569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2023_sep_28'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path+date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "86defda7-46ef-4cd2-9f41-67d9644e838c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kaanhamilton/JupyterProjects/truthchance/NewsScraping/data/guardian_articles/opinion/2023_sep_28 is created!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953a731-7507-452a-88ee-50f805185064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
